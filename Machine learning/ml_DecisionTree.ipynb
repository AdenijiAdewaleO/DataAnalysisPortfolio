{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Sklearn for model fitting and scroing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>var_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  \\\n",
       "69        1  0.661  0.967  0.760  0.183  0.696  0.248  0.003  0.445  0.184   \n",
       "115       0  0.830  0.321  0.110  0.893  0.282  0.338  0.193  0.495  0.173   \n",
       "45        1  0.527  0.432  0.164  0.568  0.747  0.474  0.187  0.303  0.381   \n",
       "81        1  0.028  0.706  0.018  0.984  0.564  0.831  0.697  0.032  0.414   \n",
       "11        0  0.716  0.534  0.857  0.493  0.963  0.852  0.975  0.176  0.048   \n",
       "\n",
       "     ...  var_191  var_192  var_193  var_194  var_195  var_196  var_197  \\\n",
       "69   ...    0.489    0.815    0.085    0.969    0.920    0.199    0.159   \n",
       "115  ...    0.339    0.167    0.326    0.359    0.414    0.728    0.539   \n",
       "45   ...    0.566    0.369    0.069    0.086    0.370    0.446    0.623   \n",
       "81   ...    0.085    0.511    0.551    0.914    0.061    0.850    0.977   \n",
       "11   ...    0.348    0.794    0.487    0.749    0.630    0.919    0.448   \n",
       "\n",
       "     var_198  var_199  var_200  \n",
       "69     0.323    0.382    0.491  \n",
       "115    0.281    0.220    0.848  \n",
       "45     0.310    0.284    0.195  \n",
       "81     0.557    0.624    0.935  \n",
       "11     0.112    0.050    0.385  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(\"../Data/training.csv\")\n",
    "df = df.drop(columns={\"id\"})\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting\n",
    "\n",
    "The first stage will be to look at the data in an initial exploratory data analysis. We know that our data is made up of numerical variables and is in a standardized form. The records are complete and there are non null values, so the data is in a clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_utils\n",
    "df_eda = ml_utils.edaDF(df, \"target\")\n",
    "num_var = list(df.columns)\n",
    "df_eda.setNum(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9908c2277b9b49b9b41a295275bffc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output()), selected_index=0, titles=('Info', 'Statistics', 'Catego…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eda.fullEDA()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 201)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting\n",
    "\n",
    "As mentioned above, our data is in a clean state and as such, we will proceed to model fitting. \n",
    "The model that is used is the DecisionTreeClassifier.\n",
    "Conidering that the data set is small-sized (250 rows of data), we will use a 70/30 percent split for the train/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df[\"target\"]).reshape(-1,1)\n",
    "X = np.array(df.drop(columns={\"target\"}))\n",
    "\n",
    "#train size = 70%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Here, the DecisionTreeClassifier is used with default hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.6266666666666667\n"
     ]
    }
   ],
   "source": [
    "pipeline_model1 = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('DT', DecisionTreeClassifier(random_state=0))\n",
    "    ]\n",
    "\n",
    "model1 = Pipeline(pipeline_model1)\n",
    "model1 = model1.fit(X_train, y_train)\n",
    "print(\"Training Accuracy:\", model1.score(X_train, y_train))\n",
    "print(\"Testing Accuracy:\", model1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: The DecisionTreeClassifier is used with the criterion set to \"entropy\". \n",
    "We noticed that there is not so much difference in the testing accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.6133333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_model2 = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('DT', DecisionTreeClassifier(random_state=0, criterion=\"entropy\"))\n",
    "    ]\n",
    "model2 = Pipeline(pipeline_model2)\n",
    "model2 = model2.fit(X_train, y_train)\n",
    "print(\"Training Accuracy:\", model2.score(X_train, y_train))\n",
    "print(\"Testing Accuracy:\", model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: The DecisionTreeClassifier is used with the criterion set default and max_depth set to 5. \n",
    "There was improvement in the testing accuracy while the traininig accuracy dropped slightly. This was considered as the best model because further tuning seems not to yield better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9257142857142857\n",
      "Testing Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "#Build pipeline\n",
    "pipeline_best = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('DT', DecisionTreeClassifier(random_state=0, max_depth=5))\n",
    "    ]\n",
    "\n",
    "best = Pipeline(pipeline_best)\n",
    "best = best.fit(X_train, y_train)\n",
    "print(\"Training Accuracy:\", best.score(X_train, y_train))\n",
    "print(\"Testing Accuracy:\", best.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('DT', DecisionTreeClassifier(max_depth=5, random_state=0))])\n"
     ]
    }
   ],
   "source": [
    "print(best.score(X_test, y_test))\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5429167644854836\n",
      "0.5427848101265823\n",
      "Adewale Adeniji 0.542850787306033\n"
     ]
    }
   ],
   "source": [
    "#Load Test Data\n",
    "test_df = pd.read_csv(\"testing.csv\")\n",
    "test_df = test_df.drop(columns={\"id\"})\n",
    "#Create tests and score\n",
    "test_y = np.array(test_df[\"target\"]).reshape(-1,1)\n",
    "test_X = np.array(test_df.drop(columns={\"target\"}))\n",
    "\n",
    "preds = best.predict(test_X)\n",
    "\n",
    "roc_score = roc_auc_score(test_y, preds)\n",
    "acc_score = accuracy_score(test_y, preds)\n",
    "\n",
    "print(roc_score)\n",
    "print(acc_score)\n",
    "print(name, np.mean([roc_score, acc_score]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Accuracy Changes Were Used\n",
    "\n",
    "What was done to try to increase accuracy and/or limit overfitting:\n",
    "<ul> \n",
    "<li>The first step was to change the diffult train_size of the train_test_split to 0.7 so as to have more data for testing.\n",
    "<li>Secondly, the max_depth of the DecisionTreeClassifier was set to 5 as this was found to produce the best result for the test data.\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
